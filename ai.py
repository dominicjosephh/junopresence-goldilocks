# ai.py
def generate_reply(user_input, chat_history, personality):
    # TODO: Move AI logic here (Together AI, Llama.cpp, fallback, etc.)
    return "AI reply placeholder"

def get_models():
    # TODO: List available models (Together AI, local, etc.)
    return ["meta-llama/Llama-3-8b-chat-hf", "local-llama.cpp"]

def set_personality(personality):
    # TODO: Set personality mode for chat
    pass

def get_personality():
    # TODO: Return current personality mode
    return "Base"
